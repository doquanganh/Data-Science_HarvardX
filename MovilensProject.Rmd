---
title: "HarvardX Data Science Program"
subtitle: Movielens project
author: "Do Quang Anh"
email: mr.anhdq@gmail.com
date: "`r format(Sys.Date())`"
output:
  html_document:
    toc: yes
    df_print: paged
  pdf_document:
    number_sections: yes
    fig_caption: yes
    toc: yes
    fig_height: 3
    includes: null

---

```{r Install Packages, include=FALSE}
##Installing Packages
# List of packages for session
.packages = c("tidyverse",       #tidy alvvays and forever!
              "corrplot",        #correlation plots
              "cowplot",         #solve x-axis misalignment when plotting, and better-looking defaults for ggplots
              "gridExtra",       #combine plots
              "knitr",           #report output
              "kableExtra",      #nice tables
              "lubridate",       #date math!
              "reshape2",        #acast to create matrix
              "scales",          #get rid of scientific notation in charts
              "splitstackshape",  #explode pipe-delimited data to one-hot encoded dummy variables
              "dplyr",
              "tm",
              "tmap",
              "wordcloud"
             
              )
# Install CRAN packages (if not already installed)
.inst <- .packages %in% installed.packages()
if(length(.packages[!.inst]) > 0) install.packages(.packages[!.inst])
# Load packages into session 
lapply(.packages, require, character.only=TRUE)

```

```{r Functions and Hooks, include=FALSE}
# Customize knitr output
#Set Thousands Separator for inline output
knitr::knit_hooks$set(inline = function(x) { if(!is.numeric(x)){ x }else{ prettyNum(round(x,2), big.mark=",") } })
#we've already set the graphic device to "png" in the RMD options. the default device for pdfs draws every point of a scatterplot, creatinvg *very* big files.
#But png is not as crisp, so we will set a higher resolution for pdf output of plots. 
knitr::opts_chunk$set(dpi=300)
#Create Kable wrapper function for thousands separator in table output, and nice formating with kableExtra
niceKable = function(...) {
  knitr::kable(..., format.args = list(decimal.mark = '.', big.mark = ",")) %>% kable_styling()
}
RMSE <- function(true_ratings, predicted_ratings){
        sqrt(mean((true_ratings - predicted_ratings)^2))
}
```

# Overview

This project is related to the MovieLens Project of the HervardX: PH125.9x Data Science: Capstone course. The present report start with a general idea of the project and by representing its objectif.

Then the given dataset will be prepared and setup. An exploratory data analysis is carried out in order to develop a machine learning algorithm that could predict movie ratings until a final model. Results will be explained. Finally the report ends with some concluding remarks.

## Introduction

Recommendation systems use ratings that users have given to items to make specific recommendations. Companies that sell many products to many customers and permit these customers to rate their products, like Amazon, are able to collect massive datasets that can be used to predict what rating a particular user will give to a specific item. Items for which a high rating is predicted for a given user are then recommended to that user. 

The same could be done for other items, as movies for instance in our case. Recommendation systems are one of the most used models in machine learning algorithms. In fact the success of Netflix is said to be based on its strong recommendation system. The Netflix prize (open competition for the best collaborative filtering algorithm to predict user ratings for films, based on previous ratings without any other information about the users or films), in fact, represent the high importance of algorithm for products recommendation system.

For this project we will focus on create a movie recommendation system using the 10M version of MovieLens dataset, collected by GroupLens Research.


## Aim of the project

The aim in this project is to train a machine learning algorithm that predicts user ratings (from 0.5 to 5 stars) using the inputs of a provided subset  (edx dataset provided by the staff) to predict movie ratings in a provided validation set.

The value used to evaluate algorithm performance is the Root Mean Square Error, or RMSE. RMSE is one of the most used measure of the differences between values predicted by a model and the values observed. RMSE is a measure of accuracy, to compare forecasting errors of different models for a particular dataset, a lower RMSE is better than a higher one. The effect of each error on RMSE is proportional to the size of the squared error; thus larger errors have a disproportionately large effect on RMSE. Consequently, RMSE is sensitive to outliers.
Four models that will be developed will be compared using their resulting RMSE in order to assess their quality. The evaluation criteria for this algorithm is a RMSE expected to be lower than 0.8775.
The function that computes the RMSE for vectors of ratings and their corresponding predictors will be the following:
$$ RMSE = \sqrt{\frac{1}{N}\displaystyle\sum_{u,i} (\hat{y}_{u,i}-y_{u,i})^{2}} $$


Finally, the best resulting model will be used to predict the movie ratings.


## Dataset
The MovieLens dataset is automatically downloaded

• [MovieLens 10M dataset] https://grouplens.org/datasets/movielens/10m/

• [MovieLens 10M dataset - zip file] http://files.grouplens.org/datasets/movielens/ml-10m.zip

# Methods/Analysis
## Setting the Data

First the data is imported and partitioned. Normally, the code below would be used.

```{r Set Data example, eval=FALSE, echo=TRUE, cache=TRUE}
##########################################################
# Create edx set, validation set (final hold-out test set)
##########################################################

# Note: this process could take a couple of minutes

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")

library(tidyverse)
library(caret)
library(data.table)

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")

# if using R 4.0 or later:
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(movieId),
                                            title = as.character(title),
                                            genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding") # if using R 3.5 or earlier, use `set.seed(1)`
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
      semi_join(edx, by = "movieId") %>%
      semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)
saveRDS(edx, file = "edx.rds")
saveRDS(validation, file = "validation.rds")
```

```{r Set Data real, echo=TRUE, eval=TRUE}
#Load the Data
edx <- readRDS("edx.rds", refhook = NULL)
validation <- readRDS("validation.rds", refhook = NULL)

```

### Dataset Dimenions
```{r eval=FALSE, include=FALSE}
#Check Dimensions of both test and train set
dim(edx)
dim(validation)
```

Our training set is edx and test set is validation. Together, there are `r nrow(validation)+nrow(edx)` records 
```{r echo=FALSE}
tribble(
  ~"Dataset",     ~"Number of Rows",    ~"Number of Columns",
  #--             |--                   |----
  "edx",          nrow(edx),            ncol(edx),
  "validation",   nrow(validation),     ncol(validation)
)%>%niceKable

```
After generating codes provided in the project overview, we can see that the edX dataset is made of 6 features for a total of about `r nrow(edx)` observations.The validation set which represents 10% of the 10M Movielens dataset contains the same features , but with a total of `r nrow(validation)` occurences. we made sure that userId and movieId in edx set are also in validation set.

Each row represents a rating given by one user to one movie. The column “rating” is the outcome we want to predict, y. Taking into account both datasets, here are the features and their characteristics:

***quantitative features***

-userId : discrete, Unique ID for the user.

-movieId: discrete, Unique ID for the movie.

-timestamp : discrete , Date and time the rating was given.

***qualitative features***

-title: nominal , movie title (not unique)

-genres: nominal, genres associated with the movie.

***outcome,y***

-rating : continuous, a rating between 0 and 5 for the movie.


**Check missing value in edx. There are no missing values in any column.**

```{r}
sapply(edx, {function(x) any(is.na(x))})%>% niceKable
```

A preview of the data structure is shown below from the first few rows in 'edx'.


```{r echo=FALSE, message=FALSE, warning=FALSE}

head(edx)  %>% kable %>% kable_styling()
```
Rating is the dependent/target variable - the value we are tring to predict.

\newpage

### Data Classes
We can see that userId, movieId and rating are not factors, despite each having a smaller number of unique values. Furthermore, timestamp (the timestamp of the rating) is not useful as an integer.
```{r echo=FALSE}
sapply(edx,class) %>% niceKable
```
### Genres

```{r cache=TRUE, include=FALSE}
genre_count <- edx %>% separate_rows(genres, sep="\\|") %>% group_by(genres) %>% summarise(number = n()) %>% arrange(desc(number))

```

While there are only `r nrow(genre_count)` unique genres, a film may be classified into multiple genres, up to seven at once. There are `r n_distinct(edx$genres)` of these unique combinations. Here are some of the biggest combinations.
```{r echo=FALSE, message=FALSE, warning=FALSE}
edx %>%
  distinct(genres) %>%
  mutate(genreCount = str_count(genres,'\\|')) %>%
  arrange(desc(genreCount)) %>%
  top_n(2) %>%
  niceKable
```
### Best-Rated Genres

Which genre combinations have the best average ratings? We'll look only at the top 10 genres from all genres that have over **10,0000** ratings. Each genre will have an error bar with the standard error of the rating.
\newpage

```{r fig.height=7, echo=FALSE,warning=FALSE}
top10kgenres <- edx %>%
  group_by(genres) %>%
  summarize(n=n(), sd=sd(rating), se = sd/sqrt(n), avg = mean(rating)) %>%
  filter(n>10000) %>%
  top_n(10,avg) %>%
  mutate(genres=reorder(genres,avg))

top10Kplot <- top10kgenres %>% ggplot(aes(x=genres, y=avg))+
  geom_point()+
  geom_errorbar(aes(ymin=avg-se, ymax=avg+se, width=0.4, colour="red",alpha=0.4, size=1.3))+
  theme(axis.text.x = element_text(angle=60, hjust = 1))+
  ggtitle("Top Genres > 10,000 Ratings")+
  ylim(3.5,4.3)
top100Kgenres <- edx %>%
  group_by(genres) %>%
  summarize(  n = n(),sd = sd(rating) ,se  = sd/sqrt(n) ,avg = mean(rating)) %>%
  filter(n > 100000) %>%
  top_n(10, avg) %>%
	mutate(genres = reorder(genres, avg))

top100Kplot <- top100Kgenres %>% ggplot (aes(x=genres, y=avg)) +
    geom_point() +
    geom_errorbar(aes(ymin=avg-se, ymax=avg+se), width=0.4, colour="red", alpha=0.4, size=1.3) +
    theme(axis.text.x = element_text(angle = 60, hjust = 1))+
    ggtitle("Top Genres > 100,000 Ratings") +
    ylim(3.4, 4.3)  


#align x-axes of both plots
topplots <- align_plots(top10Kplot, top100Kplot, align = "hv")
grid.arrange(topplots[[1]],topplots[[2]], nrow=1)

```

### Genre prevalence
We may later decide to split these genre combinations up for better predictive value. Let's look at the individual prevalence of ratings each genre.

```{r echo=FALSE}

genre_count %>% 
  ggplot(aes(reorder(genres, number), number)) +
  geom_bar(stat = "identity", fill="steelblue") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_y_continuous(labels = comma)

```
As expected, we can see some users are prolific, rating many movies. Likewise, some movies are very commonly rated.

```{r}
library("tm")
layout(matrix(c(1,2), nrow =2) , heights = c(1,4))
par(mar=rep(0,4))
plot.new()
text(x=0.5,y=0.5, "top Genres by number of ratings")
wordcloud(words=genre_count$genres,freq=genre_count$number,min.freq=50,
          max.words = 20,random.order=FALSE,random.color=FALSE,
          rot.per=0.35,colors = brewer.pal(8,"Dark2"),scale=c(5,.2),
          family="plain",font=2,
          main = "Top genres by number of ratings")
```





### Reviews 

Which films have the most popular(most rating)?

```{r Rating Frequency, echo=FALSE, message=FALSE, warning=FALSE}
edx %>%
  group_by(title) %>%
  summarize(count = n()) %>%
  arrange(-count) %>%
  top_n(20, count) %>%
  ggplot(aes(count, reorder(title, count))) +
  geom_bar(color = "black", fill = "deepskyblue2", stat = "identity") +
  geom_text(aes(label=count), vjust="top", color="black", size=3) + #add counts to bars themselves...
  xlab("Count") +
  ylab(NULL) +
  theme_bw()
```
\newpage

### Rating Frequency

Half-star ratings are given out less frequently than full-stars. 4-star and 3-star ratings are the most common, followed by 5-star ratings.

```{r fig.height=3, echo=FALSE}
edx %>%
  group_by(rating) %>%
  summarize(count = n(),probability = count/nrow(edx)) %>%
  ggplot(aes(rating, count))+
  geom_bar(stat="identity", fill ="deepskyblue2")+
  geom_text(aes(label=count), vjust="top", color="white", size=3)+
  theme_minimal() +
  theme(axis.title.y=element_blank(),                                 #.,. and hide y-axis labels
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())
  
```